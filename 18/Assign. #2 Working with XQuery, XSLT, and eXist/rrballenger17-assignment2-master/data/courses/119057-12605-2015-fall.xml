<?xml version="1.0" encoding="UTF-8"?>
<courses>
    <course academic_year="2015" course_id="119057" class_number="12605" school_id="fas" section="001" term_code="fall">
        <catalog_info>
            <title short_title="ENG-SCI 250">Information Theory</title>
            <exam_group>FAS15_A</exam_group>
            <prereq>Recommended: Engineering Sciences 150 or knowledge of basic probability.</prereq>
            <description>Fundamental concepts of information theory, Entropy, Kullback-Leibler divergence, Mutual information; typical sequences and their applications, Loss-less data compression, Huffman codes, Elias Codes, Arithmetic Codes, Discrete Memory-less Channels, Channel Coding and Capacity, Differential Entropy, Gaussian Channels, rate distortion theory, Multi-user Information Theory, Connections between information theory and statistics.</description>
            <department code="ENGSCI">Engineering Sciences</department>
            <course_group code="ENG-SCI">Engineering Sciences</course_group>
            <course_type>Lecture</course_type>
            <credits>4</credits>
            <meeting_schedule>
                <meeting days_of_week="Tuesday Thursday" end_time="14:29:00" location="Maxwell Dworkin 223 (SEAS)" start_time="13:00:00"/>
            </meeting_schedule>
            <exam_date>2015-12-19</exam_date>
        </catalog_info>
        <staff>
            <person id="d1e270649a1310" role="1" seniority_sort="1">
                <display_name>Christ Richmond</display_name>
            </person>
        </staff>
    </course>
</courses>